#!/bin/bash -u
# Copyright 2018 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
################################################################################

set -x

cd $OUT

if (( $# > 0 )); then
  FUZZ_TARGETS="$@"
else
  FUZZ_TARGETS="$(find . -maxdepth 1 -type f -executable -printf '%P\n' | \
      grep -v -x -F \
      -e 'llvm-symbolizer' \
      -e 'jazzer_agent_deploy.jar' \
      -e 'jazzer_driver' \
      -e 'jazzer_driver_with_sanitizer' \
      -e 'sanitizer_with_fuzzer.so')"
fi

COVERAGE_OUTPUT_DIR=${COVERAGE_OUTPUT_DIR:-$OUT}

DUMPS_DIR="$COVERAGE_OUTPUT_DIR/dumps"
FUZZERS_COVERAGE_DUMPS_DIR="$DUMPS_DIR/fuzzers_coverage"
MERGED_COVERAGE_DIR="$COVERAGE_OUTPUT_DIR/merged_coverage"
FUZZER_STATS_DIR="$COVERAGE_OUTPUT_DIR/fuzzer_stats"
TEXTCOV_REPORT_DIR="$COVERAGE_OUTPUT_DIR/textcov_reports"
LOGS_DIR="$COVERAGE_OUTPUT_DIR/logs"
REPORT_ROOT_DIR="$COVERAGE_OUTPUT_DIR/report"
REPORT_BY_TARGET_ROOT_DIR="$COVERAGE_OUTPUT_DIR/report_target"
PLATFORM=linux
REPORT_PLATFORM_DIR="$COVERAGE_OUTPUT_DIR/report/$PLATFORM"

for directory in $DUMPS_DIR $FUZZER_STATS_DIR $LOGS_DIR $REPORT_ROOT_DIR $TEXTCOV_REPORT_DIR\
                 $REPORT_PLATFORM_DIR $REPORT_BY_TARGET_ROOT_DIR $FUZZERS_COVERAGE_DUMPS_DIR $MERGED_COVERAGE_DIR; do
  rm -rf $directory
  mkdir -p $directory
done

# TODO(rui): need to change
PROFILE_FILE="$DUMPS_DIR/merged.profdata"
SUMMARY_FILE="$REPORT_PLATFORM_DIR/summary.json"
COVERAGE_TARGET_FILE="$FUZZER_STATS_DIR/coverage_targets.txt"

# Use path mapping, as $SRC directory from the builder is copied into $OUT/$SRC.
PATH_EQUIVALENCE_ARGS="-path-equivalence=/,$OUT"

# It's important to use $COVERAGE_EXTRA_ARGS as the last argument, because it
# can contain paths to source files / directories which are positional args.
LLVM_COV_COMMON_ARGS="$PATH_EQUIVALENCE_ARGS \
    -ignore-filename-regex=.*src/libfuzzer/.* $COVERAGE_EXTRA_ARGS"

# Options to extract branch coverage.
BRANCH_COV_ARGS="--show-branches=count --show-expansions"

# Timeout for running a single fuzz target.
TIMEOUT=1h

# This will be used by llvm-cov command to generate the actual report.
objects=""

# Number of CPUs available, this is needed for running tests in parallel.
# Set the max number of parallel jobs to be the CPU count and a max of 10.
NPROC=$(nproc)
MAX_PARALLEL_COUNT=10

CORPUS_DIR=${CORPUS_DIR:-"/corpus"}

function run_fuzz_target {
  local target=$1

  # Base directory where corpus snapshots are stored for this target
  local corpus_base="$CORPUS_DIR/${target}_backup"

  # Collect all corpus snapshot directories
  local corpus_snapshots=()
  while IFS= read -r -d '' dir; do
    corpus_snapshots+=("$dir")
  done < <(find "$corpus_base" -maxdepth 1 -type d -name 'backup_*' -print0)

  # Check if any snapshots are found
  if [ ${#corpus_snapshots[@]} -eq 0 ]; then
    echo "No corpus snapshots found for target $target in $corpus_base"
    return 0
  fi

  # Process each snapshot independently
  for corpus_dir in "${corpus_snapshots[@]}"; do
    # Extract timestamp or unique identifier from the snapshot directory name
    snapshot_name=$(basename $corpus_dir)
    # Example: snapshot_name could be 'backup_20230101000000'

    # '%1m' will produce separate dump files for every object
    local profraw_file="$DUMPS_DIR/${target}/${snapshot_name}.%1m.profraw"
    local profraw_file_mask="$DUMPS_DIR/${target}/${snapshot_name}.*.profraw"
    local profdata_file="$DUMPS_DIR/${target}/${snapshot_name}.profdata"

    # -merge=1 requires an output directory, create a new, empty dir for that
    local corpus_dummy="$OUT/dummy_corpus_dir_for_${target}_${snapshot_name}"
    rm -rf $corpus_dummy && mkdir -p $corpus_dummy

    # Prepare the arguments for the fuzzer
    local args="-merge=1 -timeout=100 $corpus_dummy $corpus_dir"

    export LLVM_PROFILE_FILE="$profraw_file"
    timeout $TIMEOUT $OUT/$target $args &> $LOGS_DIR/${target}_${snapshot_name}.log
    if (( $? != 0 )); then
      echo "Error occurred while running $target on snapshot: $snapshot_name"
      cat $LOGS_DIR/${target}_${snapshot_name}.log
    fi

    rm -rf $corpus_dummy

    # Check if profraw files were generated
    if (( $(du -c $profraw_file_mask | tail -n 1 | cut -f 1) == 0 )); then
      # Skip if no profile dumps were generated
      echo "No profile dumps generated for snapshot $snapshot_name of target $target"
      continue
    fi

    # If necessary, translate to the latest profraw version
    if [[ $target == *"@"* ]]; then
      # Extract fuzztest binary name from fuzztest wrapper script
      target=(${target//@/ }[0])
    fi

    profraw_update.py $OUT/$target -i $profraw_file_mask
    llvm-profdata merge -j=1 -sparse $profraw_file_mask -o $profdata_file

    # Delete unnecessary and potentially large .profraw files
    rm $profraw_file_mask

    shared_libraries=$(coverage_helper shared_libs -build-dir=$OUT -object=$target)

    # Generate coverage report for this snapshot
    llvm-cov export -instr-profile=$profdata_file -object=$target \
        $shared_libraries $LLVM_COV_COMMON_ARGS > $FUZZER_STATS_DIR/${target}_${snapshot_name}.json

    # For introspector
    llvm-cov show -instr-profile=$profdata_file -object=$target -line-coverage-gt=0 \
        $shared_libraries $BRANCH_COV_ARGS $LLVM_COV_COMMON_ARGS > ${TEXTCOV_REPORT_DIR}/${target}_${snapshot_name}.covreport

    # output progress
    echo "Processed snapshot $snapshot_name for target $target"
  done
}

function run_python_fuzz_target {
  local target=$1

  local corpus_base="$CORPUS_DIR/${target}_backup"

  local corpus_snapshots=()
  while IFS= read -r -d '' dir; do
    corpus_snapshots+=("$dir")
  done < <(find "$corpus_base" -maxdepth 1 -type d -name 'backup_*' -print0)

  # Check if any snapshots are found
  if [ ${#corpus_snapshots[@]} -eq 0 ]; then
    echo "No corpus snapshots found for target $target in $corpus_base"
    return 0
  fi

  # Process each snapshot independently
  for corpus_dir in "${corpus_snapshots[@]}"; do
    snapshot_name=$(basename $corpus_dir)

    local zipped_sources="$DUMPS_DIR/${target}/${snapshot_name}.deps.zip"
    local corpus_real=$corpus_dir
    # # Write dummy stats file
    # echo "{}" > "$FUZZER_STATS_DIR/${target}_${snapshot_name}.json"

    $OUT/$target $corpus_real -atheris_runs=$(ls -la $corpus_real | wc -l) > $LOGS_DIR/${target}_${snapshot_name}.log 2>&1
    if (( $? != 0 )); then
      echo "Error happened getting coverage of $target"
      echo "This is likely because Atheris did not exit gracefully"
      cat $LOGS_DIR/${target}_${snapshot_name}.log
      return 0
    fi
    mv .coverage $OUT/.coverage_${target}_${snapshot_name}
  done
}

function generate_html {
  local profdata=$1
  local shared_libraries=$2
  local objects=$3
  local output_dir=$4

  rm -rf "$output_dir"
  mkdir -p "$output_dir/$PLATFORM"

  local llvm_cov_args="-instr-profile=$profdata $objects $LLVM_COV_COMMON_ARGS"
  llvm-cov show -format=html -output-dir=$output_dir -Xdemangler rcfilt $llvm_cov_args

  # Export coverage summary in JSON format.
  local summary_file=$output_dir/$PLATFORM/summary.json

  llvm-cov export $llvm_cov_args > $summary_file

  coverage_helper -v post_process -src-root-dir=/ -summary-file=$summary_file \
      -output-dir=$output_dir $PATH_EQUIVALENCE_ARGS
}

# Run each fuzz target, generate raw coverage dumps.
for fuzz_target in $FUZZ_TARGETS; do
  if [[ $FUZZING_LANGUAGE == "python" ]]; then
    echo "Entering python fuzzing"
    # Log the target in the targets file.
    echo ${fuzz_target} >> $COVERAGE_TARGET_FILE

    # Run the coverage collection.
    run_python_fuzz_target $fuzz_target
  else
    # Continue if not a fuzz target.
    if [[ $FUZZING_ENGINE != "none" ]]; then
      grep "LLVMFuzzerTestOneInput" $fuzz_target > /dev/null 2>&1 || continue
    fi

    echo "Running $fuzz_target"
    # Log the target in the targets file.
    echo ${fuzz_target} >> $COVERAGE_TARGET_FILE

    # Run the coverage collection.
    run_fuzz_target $fuzz_target &

    # Rewrite object if its a FUZZTEST target
    if [[ $fuzz_target == *"@"* ]]; then
      # Extract fuzztest binary name from fuzztest wrapper script.
      fuzz_target=(${fuzz_target//@/ }[0])
    fi
    if [[ -z $objects ]]; then
      # The first object needs to be passed without -object= flag.
      objects="$fuzz_target"
    else
      objects="$objects -object=$fuzz_target"
    fi
  fi


  # Limit the number of processes to be spawned.
  n_child_proc=$(jobs -rp | wc -l)
  while [[ "$n_child_proc" -eq "$NPROC" || "$n_child_proc" -gt "$MAX_PARALLEL_COUNT" ]]; do
    sleep 4
    n_child_proc=$(jobs -rp | wc -l)
  done
done

# Wait for background processes to finish.
wait

if [[ $FUZZING_LANGUAGE == "python" ]]; then
  # Extract source files from all dependency zip folders
  mkdir -p /pythoncovmergedfiles/medio
  for fuzzer in $FUZZ_TARGETS; do
    fuzzer_deps=${fuzzer}.pkg.deps.zip
    unzip $OUT/${fuzzer_deps}
    rsync -r ./medio /pythoncovmergedfiles/medio
    rm -rf ./medio

    coverage_snapshots=()
    while IFS= read -r -d '' file; do
      coverage_snapshots+=("$file")
    done < <(find "$OUT" -maxdepth 1 -type f -name ".coverage_${fuzzer}_backup_*" -print0)

    # Check if any snapshots are found
    if [ ${#coverage_snapshots[@]} -eq 0 ]; then
      echo "No coverage snapshots found for target $fuzzer in $OUT"
    fi

    for coverage_snapshot in "${coverage_snapshots[@]}"; do
      snapshot_name=$(echo "$coverage_snapshot" | awk -F'_' '{print $NF}')
      # Translate paths in unzipped folders to paths that we can use
      mv $coverage_snapshot .coverage
      python3 /usr/local/bin/python_coverage_runner_help.py translate /pythoncovmergedfiles/medio

      # Generate coverage report for this snapshot
      python3 /usr/local/bin/python_coverage_runner_help.py json --data-file=.new_coverage -o ${TEXTCOV_REPORT_DIR}/${fuzzer}/${snapshot_name}.json

    done
  done
else

  # From this point on the script does not tolerate any errors.
  set -e

  # Skip merging all dumps

  # TODO(mmoroz): add script from Chromium for rendering directory view reports.
  # The first path in $objects does not have -object= prefix (llvm-cov format).
  shared_libraries=$(coverage_helper shared_libs -build-dir=$OUT -object=$objects)
  objects="$objects $shared_libraries"

  # Per target reports.
  for fuzz_target in $FUZZ_TARGETS; do
    profdata_snapshots=()
    while IFS= read -r -d '' file; do
        profdata_snapshots+=("$file")
    done < <(find "$DUMPS_DIR/$fuzz_target" -maxdepth 1 -type f -name "backup_*.profdata" -print0)
    
    for profdata in "${profdata_snapshots[@]}"; do
        if [[ $fuzz_target == *"@"* ]]; then
            profdata_path=$profdata
            report_dir=$REPORT_BY_TARGET_ROOT_DIR/$fuzz_target
            # Extract fuzztest binary name from fuzztest wrapper script.
            fuzz_target=(${fuzz_target//@/ }[0])
        else
            profdata_path=$profdata
            report_dir=$REPORT_BY_TARGET_ROOT_DIR/$fuzz_target/$(basename $profdata .profdata)
        fi
        if [[ ! -f "$profdata_path" ]]; then
            echo "WARNING: $fuzz_target has no profdata generated."
            continue
        fi
        generate_html $profdata_path "$shared_libraries" "$fuzz_target" "$report_dir"
    done
  done

  set +e
fi

# Make sure report is readable.
chmod -R +r $REPORT_ROOT_DIR $REPORT_BY_TARGET_ROOT_DIR
find $REPORT_ROOT_DIR $REPORT_BY_TARGET_ROOT_DIR -type d -exec chmod +x {} +

# HTTP_PORT is optional.
set +u
if [[ -n $HTTP_PORT ]]; then
  # Serve the report locally.
  echo "Serving the report on http://127.0.0.1:$HTTP_PORT/linux/index.html"
  cd $REPORT_ROOT_DIR
  python3 -m http.server $HTTP_PORT
fi
